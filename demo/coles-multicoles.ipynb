{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eff19c5",
   "metadata": {},
   "source": [
    "# Multicoles modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af482de9",
   "metadata": {},
   "source": [
    "In this notebook we will learn how to use multicoles modules. Instead of training one model they train two separete models with constraint on mutual information of built embeddings. There are two approaches:\n",
    "There are two approaches:\n",
    "1) Train two model sequentially. So that second model trained while first is frozen.\n",
    "2) Train both model simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fd2f3",
   "metadata": {},
   "source": [
    "## Sequential approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395e749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2024-08-30 06:04:22.028569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/al/Applications/miniconda3/envs/rlbnb/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ptls\n",
    "import pytorch_lightning as pl\n",
    "import ptls.frames\n",
    "import ptls.frames.coles\n",
    "from ptls.data_load.datasets import ParquetFiles, ParquetDataset, MemoryMapDataset\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.coles import ColesDataset, ColesIterableDataset\n",
    "from ptls.frames.supervised import SeqToTargetIterableDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.nn.normalization import L2NormEncoder\n",
    "from ptls.frames.coles.losses import ContrastiveLoss, MultiContrastiveLoss, CLUBLoss\n",
    "from ptls.frames.coles.sampling_strategies import HardNegativePairSelector\n",
    "from ptls.frames.coles.metric import BatchRecallTopK, MultiBatchRecallTopK\n",
    "from functools import partial\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1ab68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "def get_synthetic_coles_datamodule():\n",
    "    path = \"./syndata/example_data/\"\n",
    "\n",
    "    train_files = ParquetFiles(os.path.join(path, \"train\"))\n",
    "    train_dataset = ParquetDataset(train_files, shuffle_files=True)\n",
    "    eval_files = ParquetFiles(os.path.join(path, \"eval\"))\n",
    "    eval_dataset = ParquetDataset(eval_files)\n",
    "\n",
    "    coles_datamodule = PtlsDataModule(\n",
    "        train_data=ColesIterableDataset(\n",
    "            train_dataset,\n",
    "            splitter=SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=50,\n",
    "                cnt_max=100,\n",
    "            ),\n",
    "        ),\n",
    "        valid_data=ColesIterableDataset(\n",
    "            eval_dataset,\n",
    "            splitter=SampleSlices(\n",
    "                split_count=5,\n",
    "                cnt_min=50,\n",
    "                cnt_max=100, ),\n",
    "        ),\n",
    "        train_num_workers=4,\n",
    "        train_batch_size=512,\n",
    "        valid_num_workers=4,\n",
    "        valid_batch_size=512,\n",
    "    )\n",
    "\n",
    "    return coles_datamodule\n",
    "\n",
    "data = get_synthetic_coles_datamodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83b92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coles module\n",
    "\n",
    "def get_coles_module(trx_conf, input_size, hsize):\n",
    "    pl_module = ptls.frames.coles.CoLESModule(\n",
    "        validation_metric=BatchRecallTopK(K=4, metric='cosine'),\n",
    "        seq_encoder=ptls.nn.RnnSeqEncoder(\n",
    "            trx_encoder=ptls.nn.TrxEncoder(**trx_conf),\n",
    "            input_size=input_size,\n",
    "            type='gru',\n",
    "            hidden_size=hsize,\n",
    "            is_reduce_sequence=True\n",
    "        ),\n",
    "        head=ptls.nn.Head(use_norm_encoder=True),\n",
    "        loss=ContrastiveLoss(\n",
    "            margin=1.,\n",
    "            sampling_strategy=HardNegativePairSelector(neg_count=5),\n",
    "        ),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025)\n",
    "    )\n",
    "    return pl_module\n",
    "\n",
    "\n",
    "trx_conf = {\n",
    "    'embeddings_noise': 0.001,\n",
    "    'embeddings': {\n",
    "        'A': {'in': 64, 'out': 16},\n",
    "        'B': {'in': 64, 'out': 16},\n",
    "    },\n",
    "}\n",
    "\n",
    "input_size = 16 * 2\n",
    "hsize = 32    # dimensionaliti of the encoder's hidden space\n",
    "\n",
    "coles_model = get_coles_module(trx_conf, input_size, hsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1536d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 8.4 K \n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134a66d9006a4a3fbe608e09593f7856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train it and save\n",
    "\n",
    "trainer = pl.Trainer(gpus=[0], max_epochs=10, enable_progress_bar=True)\n",
    "trainer.fit(coles_model, data)\n",
    "torch.save(coles_model.seq_encoder.state_dict(), 'first_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490c16a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "mean roc_auc: 0.5782 std : 0.0021\n"
     ]
    }
   ],
   "source": [
    "# now lets test it\n",
    "\n",
    "def get_synthetic_sup_datamodule():\n",
    "    path = \"./syndata/example_data/\"\n",
    "    \n",
    "    train_files = ParquetFiles(os.path.join(path, \"train\"))\n",
    "    train_dataset = ParquetDataset(train_files, shuffle_files=True)\n",
    "    test_files = ParquetFiles(os.path.join(path, \"eval\"))\n",
    "    test_dataset = ParquetDataset(test_files, shuffle_files=True)\n",
    "\n",
    "    sup_datamodule = PtlsDataModule(\n",
    "        train_data=SeqToTargetIterableDataset(train_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        test_data=SeqToTargetIterableDataset(test_dataset, target_col_name='class_label', target_dtype=torch.long),\n",
    "        train_batch_size=512,\n",
    "        test_batch_size=512,\n",
    "        train_num_workers=4,\n",
    "        test_num_workers=4,\n",
    "    )\n",
    "    return sup_datamodule\n",
    "\n",
    "\n",
    "def eval_dataloader(model, dl, device='cuda:0'):\n",
    "    embs, yy = list(), list()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for batch in dl:\n",
    "        x, y = batch\n",
    "        yy.append(y.numpy())\n",
    "        with torch.no_grad():\n",
    "            embs.append(model(x.to(device)).cpu().numpy())\n",
    "    return {'x': np.concatenate(embs, axis=0), 'y': np.concatenate(yy, axis=0)}\n",
    "        \n",
    "\n",
    "\n",
    "def eval_embeddings(coles_model, data):\n",
    "    train_gbm_data = eval_dataloader(coles_model, data.train_dataloader())\n",
    "    test_gbm_data = eval_dataloader(coles_model, data.test_dataloader())\n",
    "    return train_gbm_data, test_gbm_data\n",
    "\n",
    "\n",
    "def gbm(train_gbm_data, test_gbm_data):\n",
    "    accs = list()\n",
    "    for gbm_i in range(5):\n",
    "        gbm_model = LGBMClassifier(**{\n",
    "              'n_estimators': 50,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'objective': 'binary',\n",
    "              'learning_rate': 0.02,\n",
    "              'subsample': 0.75,\n",
    "              'subsample_freq': 1,\n",
    "              'feature_fraction': 0.75,\n",
    "              'colsample_bytree': None,\n",
    "              'max_depth': 12,\n",
    "              'lambda_l1': 1,\n",
    "              'reg_alpha': None,\n",
    "              'lambda_l2': 1,\n",
    "              'reg_lambda': None,\n",
    "              'min_data_in_leaf': 50,\n",
    "              'min_child_samples': None,\n",
    "              'num_leaves': 50,\n",
    "              'random_state': 42+gbm_i,\n",
    "              'n_jobs': 4,\n",
    "        })\n",
    "        \n",
    "        gbm_model.fit(train_gbm_data['x'], train_gbm_data['y'])\n",
    "        acc = roc_auc_score(test_gbm_data['y'], gbm_model.predict_proba(test_gbm_data['x'])[:, 1])\n",
    "        accs.append(acc)\n",
    "    mean, std = np.mean(accs), np.std(accs)\n",
    "    print(f'mean roc_auc: {mean:.4f} std : {std:.4f}')\n",
    "\n",
    "\n",
    "eval_datamodule = get_synthetic_sup_datamodule()\n",
    "train_gbm_data, test_gbm_data = eval_embeddings(coles_model, eval_datamodule)\n",
    "gbm(train_gbm_data, test_gbm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3657b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets train second model now\n",
    "# first of all we need some network to be our estimator for mutual information\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, h, use_layernorm=True, dropout=0):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for _ in range(2):\n",
    "            layers.append(torch.nn.Linear(h, h))\n",
    "            if use_layernorm:\n",
    "                layers.append(torch.nn.LayerNorm(h))\n",
    "            if dropout > 0:\n",
    "                layers.append(torch.nn.Dropout(dropout))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.net(inp) + inp\n",
    "\n",
    "\n",
    "class ClfDisc(torch.nn.Module):\n",
    "    def __init__(self, inp1=400, inp2=400, h=512, n_res_blocks=3, use_bn=True, use_l2_norm=True):\n",
    "        super().__init__()\n",
    "        layers_a = [torch.nn.Linear(inp1, h), torch.nn.ReLU()]\n",
    "        layers_a.extend([ResNet(h) for _ in range(n_res_blocks)])\n",
    "        if use_bn:\n",
    "            layers_a.append(torch.nn.BatchNorm1d(h, affine=False))\n",
    "        if use_l2_norm:\n",
    "            layers_a.append(L2NormEncoder())\n",
    "        self.a = torch.nn.Sequential(*layers_a)\n",
    "\n",
    "        layers_b = [torch.nn.Linear(inp2, h), torch.nn.ReLU()]\n",
    "        layers_b.extend([ResNet(h) for _ in range(n_res_blocks)])\n",
    "        if use_bn:\n",
    "            layers_b.append(torch.nn.BatchNorm1d(h, affine=False))\n",
    "        if use_l2_norm:\n",
    "            layers_b.append(L2NormEncoder())\n",
    "        self.b = torch.nn.Sequential(*layers_b)\n",
    "\n",
    "    def forward(self, domain_a, domain_b):\n",
    "        a = self.a(domain_a)\n",
    "        b = self.b(domain_b)\n",
    "        return -(((a - b) ** 2).sum(axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e427ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/al/prjs/pytorch-lifestream/ptls/frames/coles/multi_coles_module.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.trained_models[i].load_state_dict(torch.load(enc_path))\n"
     ]
    }
   ],
   "source": [
    "# now we will define and train second model\n",
    "\n",
    "def get_multicoles_module(trx_conf, input_size, embed_coef, hsize, clf_hsize, first_model_name):\n",
    "    coles_loss = ContrastiveLoss(margin=1., sampling_strategy=HardNegativePairSelector(neg_count=5))\n",
    "    club_loss = CLUBLoss()\n",
    "    discriminator_model = ClfDisc(inp1=hsize, inp2=hsize, h=clf_hsize)\n",
    "\n",
    "    seq_encoder = ptls.nn.RnnSeqEncoder(\n",
    "        trx_encoder=ptls.nn.TrxEncoder(**trx_conf),\n",
    "        input_size=input_size,\n",
    "        type='gru',\n",
    "        hidden_size=hsize,\n",
    "        is_reduce_sequence=True\n",
    "    )\n",
    "\n",
    "    pl_module = ptls.frames.coles.MultiCoLESModule(\n",
    "        head=ptls.nn.Head(use_norm_encoder=True),\n",
    "        validation_metric=BatchRecallTopK(K=4, metric='cosine'),\n",
    "        loss=coles_loss,\n",
    "        discriminator_loss=club_loss,\n",
    "        seq_encoder=seq_encoder,\n",
    "        discriminator=discriminator_model,\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "        d_optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        trained_encoders=[first_model_name],\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025),\n",
    "        coles_coef=1.,\n",
    "        embed_coef=embed_coef\n",
    "    )\n",
    "    return pl_module\n",
    "\n",
    "\n",
    "\n",
    "embed_coef = 0.1   # discriminator loss coefficent\n",
    "hsize = 32   # dimensionaliti of the encoder's hidden space\n",
    "clf_hsize = 32 * 4   # dimensionaliti of the discriminator network's hidden space\n",
    "first_model_name = 'first_model.pth'   # path to previously trained model\n",
    "\n",
    "multicoles_model = get_multicoles_module(trx_conf, input_size, embed_coef,\n",
    "                                         hsize, clf_hsize, first_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b8881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type            | Params\n",
      "------------------------------------------------------------\n",
      "0 | _loss                   | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder            | RnnSeqEncoder   | 8.4 K \n",
      "2 | _validation_metric      | BatchRecallTopK | 0     \n",
      "3 | discriminator_loss      | CLUBLoss        | 0     \n",
      "4 | trained_models          | ModuleList      | 8.4 K \n",
      "5 | discriminator           | ClfDisc         | 209 K \n",
      "6 | reference_discriminator | ClfDisc         | 209 K \n",
      "7 | _head                   | Head            | 0     \n",
      "------------------------------------------------------------\n",
      "427 K     Trainable params\n",
      "8.4 K     Non-trainable params\n",
      "436 K     Total params\n",
      "1.745     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7078f77426f44f82909d514f60372532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train it\n",
    "\n",
    "trainer = pl.Trainer(gpus=[0], max_epochs=10, enable_progress_bar=True)\n",
    "trainer.fit(multicoles_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f95af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8160\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "mean roc_auc: 0.5134 std : 0.0036\n"
     ]
    }
   ],
   "source": [
    "# and test it\n",
    "\n",
    "eval_datamodule = get_synthetic_sup_datamodule()\n",
    "train_gbm_data, test_gbm_data = eval_embeddings(multicoles_model, eval_datamodule)\n",
    "gbm(train_gbm_data, test_gbm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9f1d0",
   "metadata": {},
   "source": [
    "## Simultaneous approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec64b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need frozen model for second approach\n",
    "\n",
    "def get_multicoles_sml_module(trx_conf, input_size, embed_coef, hsize, clf_hsize):\n",
    "    coles_loss = MultiContrastiveLoss(margin=1., sampling_strategy=HardNegativePairSelector(neg_count=5))\n",
    "    club_loss = CLUBLoss()\n",
    "    discriminator_model = ClfDisc(inp1=hsize, inp2=hsize, h=clf_hsize)\n",
    "\n",
    "    seq_encoder_constructor = partial(ptls.nn.RnnSeqEncoder,\n",
    "                                      trx_encoder=ptls.nn.TrxEncoder(**trx_conf),\n",
    "                                      input_size=input_size,\n",
    "                                      type='gru',\n",
    "                                      hidden_size=hsize,\n",
    "                                      is_reduce_sequence=True\n",
    "                                      )\n",
    "    head_constructor = partial(ptls.nn.Head, use_norm_encoder=True)\n",
    "\n",
    "    pl_module = ptls.frames.coles.MultiCoLESSMLModule(\n",
    "        seq_encoder_constructor=seq_encoder_constructor,\n",
    "        head_constructor=head_constructor,\n",
    "        n_models=2,\n",
    "        discriminator=discriminator_model,\n",
    "        loss=coles_loss,\n",
    "        discriminator_loss=club_loss,\n",
    "        validation_metric=MultiBatchRecallTopK(n=2, K=4, metric='cosine'),\n",
    "        optimizer_partial=partial(torch.optim.Adam, lr=0.001, weight_decay=0.0),\n",
    "        d_optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9025),\n",
    "        coles_coef=1.,\n",
    "        embed_coef=embed_coef\n",
    "    )\n",
    "    return pl_module\n",
    "\n",
    "\n",
    "embed_coef = 0.1\n",
    "hsize = 32\n",
    "clf_hsize = 32*4\n",
    "\n",
    "multicoles_sml_model = get_multicoles_sml_module(trx_conf, input_size, embed_coef, hsize, clf_hsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0847e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                    | Type                 | Params\n",
      "-----------------------------------------------------------------\n",
      "0 | _loss                   | MultiContrastiveLoss | 0     \n",
      "1 | _seq_encoder            | ParallelModels       | 14.8 K\n",
      "2 | discriminator_loss      | CLUBLoss             | 0     \n",
      "3 | discriminator           | ClfDisc              | 209 K \n",
      "4 | reference_discriminator | ClfDisc              | 209 K \n",
      "-----------------------------------------------------------------\n",
      "434 K     Trainable params\n",
      "0         Non-trainable params\n",
      "434 K     Total params\n",
      "1.736     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f442fb17ff45eaa508e58b691005cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train it\n",
    "\n",
    "trainer = pl.Trainer(gpus=[0], max_epochs=10, enable_progress_bar=True)\n",
    "trainer.fit(multicoles_sml_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e386ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "mean roc_auc: 0.5840 std : 0.0006\n"
     ]
    }
   ],
   "source": [
    "# and test it\n",
    "\n",
    "eval_datamodule = get_synthetic_sup_datamodule()\n",
    "train_gbm_data, test_gbm_data = eval_embeddings(multicoles_sml_model, eval_datamodule)\n",
    "gbm(train_gbm_data, test_gbm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b79f33",
   "metadata": {},
   "source": [
    "## Lets compare with usual coles model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74e38091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 20.9 K\n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "20.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.9 K    Total params\n",
      "0.084     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc697ab62637436ca005858871e075d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 25600, number of negative: 25600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 51200, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "mean roc_auc: 0.5786 std : 0.0008\n"
     ]
    }
   ],
   "source": [
    "input_size = 16 * 2\n",
    "hsize = 64    # X2 hidden dimentionality\n",
    "\n",
    "mono_coles_model = get_coles_module(trx_conf, input_size, hsize)\n",
    "\n",
    "trainer = pl.Trainer(gpus=[0], max_epochs=10, enable_progress_bar=True)\n",
    "trainer.fit(mono_coles_model, data)\n",
    "\n",
    "eval_datamodule = get_synthetic_sup_datamodule()\n",
    "train_gbm_data, test_gbm_data = eval_embeddings(mono_coles_model, eval_datamodule)\n",
    "gbm(train_gbm_data, test_gbm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbd113",
   "metadata": {},
   "source": [
    "Multicolor model trained in simultaneous manner has higher score and lower dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380556f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
