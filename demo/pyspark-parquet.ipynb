{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7431993",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a798aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/transactions_train.csv'):\n",
    "    ! mkdir -p data\n",
    "    ! curl -OL https://storage.yandexcloud.net/di-datasets/age-prediction-nti-sbebank-2019.zip\n",
    "    ! unzip -j -o age-prediction-nti-sbebank-2019.zip 'data/*.csv' -d data\n",
    "    ! mv age-prediction-nti-sbebank-2019.zip data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf847b53",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587df1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f989bc",
   "metadata": {},
   "source": [
    "## Pyspark Data Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1608b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.memoryOverhead', '4g'),\n",
       " ('spark.driver.memoryOverhead', '4g'),\n",
       " ('spark.app.startTime', '1651943944680'),\n",
       " ('spark.local.dir', '../../spark_local_dir'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/mnt/mikheev/pytorch-lifestream/demo/spark-warehouse'),\n",
       " ('spark.driver.memory', '16g'),\n",
       " ('spark.executor.memory', '16g'),\n",
       " ('spark.driver.host', 'tdl3.internal.cloudapp.net'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.sql.shuffle.partitions', '200'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1651943945630'),\n",
       " ('spark.app.name', 'PysparkDataPreprocessor'),\n",
       " ('spark.cores.max', '24'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.port', '38697'),\n",
       " ('spark.driver.maxResultSize', '4g')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "\n",
    "data_path = 'data/'\n",
    "\n",
    "spark_conf = pyspark.SparkConf()\n",
    "spark_conf.setMaster(\"local[*]\").setAppName(\"PysparkDataPreprocessor\")\n",
    "spark_conf.set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "spark_conf.set(\"spark.executor.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.executor.memoryOverhead\", \"4g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.driver.memoryOverhead\", \"4g\")\n",
    "spark_conf.set(\"spark.cores.max\", \"24\")\n",
    "spark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "spark_conf.set(\"spark.local.dir\", \"../../spark_local_dir\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27115f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+----------+\n",
      "|client_id|trans_date|small_group|amount_rur|\n",
      "+---------+----------+-----------+----------+\n",
      "|    33172|         6|          4|    71.463|\n",
      "|    33172|         6|         35|    45.017|\n",
      "+---------+----------+-----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_data = spark.read.options(header=True, inferSchema=True).csv(os.path.join(data_path, 'transactions_train.csv'))\n",
    "source_data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c7afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_preprocessing import PysparkDataPreprocessor\n",
    "\n",
    "preprocessor = PysparkDataPreprocessor(\n",
    "    col_id='client_id',\n",
    "    cols_event_time='trans_date',\n",
    "    time_transformation='float',\n",
    "    cols_category=[\"trans_date\", \"small_group\"],\n",
    "    cols_log_norm=[\"amount_rur\"],\n",
    "    cols_identity=[],\n",
    "    print_dataset_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d43a15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset_pysparkdf = preprocessor.fit_transform(source_data).persist()\n",
    "dataset_pysparkdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef7582b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|client_id|          trans_date|         small_group|          amount_rur|          event_time|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      463|[726, 724, 725, 7...|[7, 1, 7, 3, 3, 2...|[0.32135927726085...|[1.0, 2.0, 5.0, 7...|\n",
      "|      471|[730, 726, 726, 7...|[68, 5, 4, 7, 1, ...|[0.26422890225828...|[0.0, 1.0, 1.0, 1...|\n",
      "|      496|[723, 723, 722, 7...|[3, 1, 1, 1, 1, 4...|[0.27119266729746...|[3.0, 3.0, 4.0, 5...|\n",
      "|      833|[726, 726, 726, 7...|[17, 15, 1, 49, 3...|[0.28922101008224...|[1.0, 1.0, 1.0, 2...|\n",
      "|     1238|[730, 723, 716, 7...|[3, 11, 3, 3, 1, ...|[0.13326234667635...|[0.0, 3.0, 9.0, 1...|\n",
      "|     1342|[730, 722, 702, 7...|[14, 3, 3, 21, 37...|[0.11547227625749...|[0.0, 4.0, 11.0, ...|\n",
      "|     1591|[724, 724, 723, 7...|[37, 20, 7, 6, 1,...|[0.35099852868535...|[2.0, 2.0, 3.0, 3...|\n",
      "|     1645|[724, 723, 723, 7...|[2, 16, 1, 1, 2, ...|[0.23653852058912...|[2.0, 3.0, 3.0, 4...|\n",
      "|     1829|[727, 716, 709, 7...|[3, 1, 3, 1, 1, 4...|[0.22955176609017...|[7.0, 9.0, 10.0, ...|\n",
      "|     1959|[723, 723, 722, 7...|[3, 1, 1, 1, 30, ...|[0.29358422166110...|[3.0, 3.0, 4.0, 5...|\n",
      "|     2122|[730, 722, 725, 7...|[38, 5, 14, 6, 3,...|[0.00341230998274...|[0.0, 4.0, 5.0, 5...|\n",
      "|     2142|[724, 724, 691, 6...|[7, 10, 1, 24, 11...|[0.29000320625500...|[2.0, 2.0, 13.0, ...|\n",
      "|     2659|[684, 688, 681, 6...|[3, 3, 36, 3, 1, ...|[0.25963118799171...|[27.0, 31.0, 39.0...|\n",
      "|     3175|[728, 728, 727, 7...|[4, 7, 1, 1, 2, 2...|[0.25272554086981...|[6.0, 6.0, 7.0, 1...|\n",
      "|     3749|[726, 722, 722, 7...|[3, 16, 35, 46, 1...|[0.23823234099543...|[1.0, 4.0, 4.0, 4...|\n",
      "|     3794|[723, 723, 722, 7...|[5, 10, 26, 26, 7...|[0.24852798380522...|[3.0, 3.0, 4.0, 7...|\n",
      "|     3997|[730, 726, 724, 7...|[3, 1, 29, 1, 1, ...|[0.35715492952800...|[0.0, 1.0, 2.0, 2...|\n",
      "|     4101|[723, 722, 725, 7...|[1, 1, 1, 13, 1, ...|[0.22094081440301...|[3.0, 4.0, 5.0, 6...|\n",
      "|     4818|[726, 724, 722, 7...|[1, 6, 6, 23, 6, ...|[0.26493123311313...|[1.0, 2.0, 4.0, 6...|\n",
      "|     4935|[723, 722, 722, 7...|[31, 31, 3, 10, 4...|[0.47558022334646...|[3.0, 4.0, 4.0, 4...|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_pysparkdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35e3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('client_id', 'int'),\n",
       " ('trans_date', 'array<int>'),\n",
       " ('small_group', 'array<int>'),\n",
       " ('amount_rur', 'array<double>'),\n",
       " ('event_time', 'array<float>')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pysparkdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3510707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dataset: 5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset 21856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of valid dataset 2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_df = dataset_pysparkdf.sample(fraction=0.2)\n",
    "train_df = dataset_pysparkdf.subtract(test_df)\n",
    "\n",
    "valid_df = train_df.sample(fraction=0.1)\n",
    "train_df = train_df.subtract(valid_df)\n",
    "\n",
    "print('Size of test dataset:', test_df.count())\n",
    "print('Size of train dataset', train_df.count())\n",
    "print('Size of valid dataset', valid_df.count())\n",
    "\n",
    "test_df.write.parquet('test.parquet')\n",
    "train_df.write.parquet('train.parquet')\n",
    "valid_df.write.parquet('valid.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65b5e3",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03032ed",
   "metadata": {},
   "source": [
    "### load SequenceEncoder obtained from `coles-emb.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb4ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ptls.seq_encoder import SequenceEncoder\n",
    "from ptls.models import Head\n",
    "from ptls.lightning_modules.emb_module import EmbModule\n",
    "\n",
    "seq_encoder = SequenceEncoder(\n",
    "    category_features=preprocessor.get_category_sizes(),\n",
    "    numeric_features=[\"amount_rur\"],\n",
    "    trx_embedding_noize=0.003\n",
    ")\n",
    "\n",
    "head = Head(input_size=seq_encoder.embedding_size, use_norm_encoder=True)\n",
    "\n",
    "model = EmbModule(seq_encoder=seq_encoder, head=head)\n",
    "\n",
    "model.load_state_dict(torch.load('coles-emb.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ab3809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train = train_df.toPandas().to_dict('records')\n",
    "for d in train:\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = np.array(v)\n",
    "\n",
    "test = test_df.toPandas().to_dict('records')\n",
    "for d in test:\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, list):\n",
    "            d[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b343bbc",
   "metadata": {},
   "source": [
    "### embedding inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c32741d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6c269916c34fc788b91250221251c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24bb0b327b849c5b9992f0500f4823c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([21856, 512]), torch.Size([5866, 512]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ptls.data_load.data_module.emb_data_module import inference_data_loader\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(gpus=1 if torch.cuda.is_available() else 0)\n",
    "\n",
    "train_dl = inference_data_loader(train, num_workers=0, batch_size=256)\n",
    "train_embeds = torch.vstack(trainer.predict(model, train_dl))\n",
    "\n",
    "test_dl = inference_data_loader(test, num_workers=0, batch_size=256)\n",
    "test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
    "\n",
    "train_embeds.shape, test_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18245f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21856, 514) (5866, 514)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_504</th>\n",
       "      <th>embed_505</th>\n",
       "      <th>embed_506</th>\n",
       "      <th>embed_507</th>\n",
       "      <th>embed_508</th>\n",
       "      <th>embed_509</th>\n",
       "      <th>embed_510</th>\n",
       "      <th>embed_511</th>\n",
       "      <th>client_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208858</td>\n",
       "      <td>-0.221062</td>\n",
       "      <td>-0.224066</td>\n",
       "      <td>-0.087435</td>\n",
       "      <td>-0.195247</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.360516</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.124512</td>\n",
       "      <td>0.078780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488976</td>\n",
       "      <td>-0.970627</td>\n",
       "      <td>0.778389</td>\n",
       "      <td>0.143021</td>\n",
       "      <td>0.521348</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>-0.045446</td>\n",
       "      <td>0.140089</td>\n",
       "      <td>4497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.256195</td>\n",
       "      <td>-0.181683</td>\n",
       "      <td>-0.223095</td>\n",
       "      <td>-0.068763</td>\n",
       "      <td>-0.159413</td>\n",
       "      <td>-0.020901</td>\n",
       "      <td>-0.075331</td>\n",
       "      <td>0.081187</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>0.146683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310049</td>\n",
       "      <td>-0.880986</td>\n",
       "      <td>0.507568</td>\n",
       "      <td>0.116876</td>\n",
       "      <td>0.536976</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-0.061394</td>\n",
       "      <td>0.124128</td>\n",
       "      <td>15439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0  0.208858 -0.221062 -0.224066 -0.087435 -0.195247  0.014467  0.360516   \n",
       "1  0.256195 -0.181683 -0.223095 -0.068763 -0.159413 -0.020901 -0.075331   \n",
       "\n",
       "    embed_7   embed_8   embed_9  ...  embed_504  embed_505  embed_506  \\\n",
       "0  0.706064  0.124512  0.078780  ...   0.488976  -0.970627   0.778389   \n",
       "1  0.081187  0.036054  0.146683  ...   0.310049  -0.880986   0.507568   \n",
       "\n",
       "   embed_507  embed_508  embed_509  embed_510  embed_511  client_id  target  \n",
       "0   0.143021   0.521348   0.109524  -0.045446   0.140089       4497       2  \n",
       "1   0.116876   0.536976   0.121534  -0.061394   0.124128      15439       1  \n",
       "\n",
       "[2 rows x 514 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# join target and embeddings\n",
    "\n",
    "df_target = pd.read_csv(os.path.join(data_path, 'train_target.csv'))\n",
    "df_target = df_target.set_index('client_id')\n",
    "df_target.rename(columns={\"bins\": \"target\"}, inplace=True)\n",
    "\n",
    "train_df = pd.DataFrame(data=train_embeds, columns=[f'embed_{i}' for i in range(train_embeds.shape[1])])\n",
    "train_df['client_id'] = [x['client_id'] for x in train]\n",
    "train_df = train_df.merge(df_target, how='left', on='client_id')\n",
    "\n",
    "test_df = pd.DataFrame(data=test_embeds, columns=[f'embed_{i}' for i in range(test_embeds.shape[1])])\n",
    "test_df['client_id'] = [x['client_id'] for x in test]\n",
    "test_df = test_df.merge(df_target, how='left', on='client_id')\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafa0c0",
   "metadata": {},
   "source": [
    "Obtained embeddings can be used as features for model training\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e3de46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5744971019434026"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embed_columns = [x for x in train_df.columns if x.startswith('embed')]\n",
    "x_train, y_train = train_df[embed_columns], train_df['target']\n",
    "x_test, y_test = test_df[embed_columns], test_df['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5b0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
