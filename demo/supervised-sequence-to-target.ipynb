{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e474f0",
   "metadata": {},
   "source": [
    "# Supervised task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c933b9",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37123d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/transactions_train.csv'):\n",
    "    ! mkdir -p data\n",
    "    ! curl -OL https://storage.yandexcloud.net/di-datasets/age-prediction-nti-sbebank-2019.zip\n",
    "    ! unzip -j -o age-prediction-nti-sbebank-2019.zip 'data/*.csv' -d data\n",
    "    ! mv age-prediction-nti-sbebank-2019.zip data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27c86e",
   "metadata": {},
   "source": [
    "## Prepare your data\n",
    "\n",
    "- Use `Pyspark` in local or cluster mode for big dataset and `Pandas` for small.\n",
    "- Split data into required parts (train, valid, test, ...).\n",
    "- Use `ptls.data_preprocessing` for simple data preparation. \n",
    "- Transform features to compatible format using `Pyspark` or `Pandas` functions. \n",
    "You can also use `ptls.data_load.preprocessing` for common data transformation patterns.\n",
    "- Split sequences to `ptls-data` format with `ptls.data_load.split_tools`. Save prepared data into `Parquet` format or \n",
    "keep it in memory (`Pickle` also works).\n",
    "- Use one of the available `ptls.data_load.datasets` to define input for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddc72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ptls.data_preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.datasets import MemoryMapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36e4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83071237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a30c6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47076</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  bins\n",
       "0      24662     2\n",
       "1       1046     0\n",
       "2      34089     2\n",
       "3      34848     1\n",
       "4      47076     3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv('data/train_target.csv')\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ae91e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 30000 records to train: 20000, valid: 3000, test: 7000\n"
     ]
    }
   ],
   "source": [
    "df_target_train, df_target_test = train_test_split(\n",
    "    df_target, test_size=7000, stratify=df_target['bins'], random_state=142)\n",
    "df_target_train, df_target_valid = train_test_split(\n",
    "    df_target_train, test_size=3000, stratify=df_target_train['bins'], random_state=142)\n",
    "print('Split {} records to train: {}, valid: {}, test: {}'.format(\n",
    "    *[len(df) for df in [df_target, df_target_train, df_target_valid, df_target_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f0eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c82aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbedfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>71.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33172</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>45.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33172</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>13.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33172</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>15.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33172</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>21.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  trans_date  small_group  amount_rur\n",
       "0      33172           6            4      71.463\n",
       "1      33172           6           35      45.017\n",
       "2      33172           8           11      13.887\n",
       "3      33172           9           11      15.983\n",
       "4      33172          10           11      21.341"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trx = pd.read_csv('data/transactions_train.csv')\n",
    "df_trx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1994f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx = df_trx.rename(columns={'trans_date': 'event_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd388c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 26450577 transactions to train: 17622321, valid: 2634248, test: 6194008\n"
     ]
    }
   ],
   "source": [
    "df_trx_train = pd.merge(df_trx, df_target_train['client_id'], on='client_id', how='inner')\n",
    "df_trx_valid = pd.merge(df_trx, df_target_valid['client_id'], on='client_id', how='inner')\n",
    "df_trx_test = pd.merge(df_trx, df_target_test['client_id'], on='client_id', how='inner')\n",
    "print('Split {} transactions to train: {}, valid: {}, test: {}'.format(\n",
    "    *[len(df) for df in [df_trx, df_trx_train, df_trx_valid, df_trx_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2eb568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba0ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform flat table to dictionaries with client features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5da2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_preprocessing import PandasDataPreprocessor\n",
    "\n",
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id='client_id',\n",
    "    cols_event_time='trans_date',\n",
    "    time_transformation='none',\n",
    "    cols_category=['small_group'],\n",
    "    cols_log_norm=[],\n",
    "    cols_identity=['amount_rur'],\n",
    "    print_dataset_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3e7618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 5.63 s, total: 33.2 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_data_train = preprocessor.fit_transform(df_trx_train)\n",
    "df_data_valid = preprocessor.transform(df_trx_valid)\n",
    "df_data_test = preprocessor.transform(df_trx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d696cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record in dataset, train 20000, valid 3000, test 7000\n",
      "Each record is a client with list of transactions\n"
     ]
    }
   ],
   "source": [
    "print('Record in dataset, train {}, valid {}, test {}\\nEach record is a client with list of transactions'.format(\n",
    "    *[len(df) for df in [df_data_train, df_data_valid, df_data_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c394a4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 6,\n",
       " 'event_time': array([ 0,  5, 10, 11, 15, 15, 16, 16, 17, 18]),\n",
       " 'small_group': array([ 4,  3,  1,  3,  4,  1,  4,  3, 18,  2]),\n",
       " 'amount_rur': array([ 4.054, 13.738, 20.701, 21.564, 13.499, 23.722,  4.304,  8.625,\n",
       "        12.938, 28.162])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 10 transactions from one record\n",
    "rec = df_data_train[0]\n",
    "{k: v[:10] if type(v) is np.ndarray else v for k, v in rec.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e7190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "509698e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71211c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_target = df_target.set_index('client_id')['bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e9bb4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_data_train, df_data_valid, df_data_test]:\n",
    "    for rec in df:\n",
    "        rec['target_bin'] = s_target.loc[rec['client_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4cbfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 6,\n",
       " 'event_time': array([ 0,  5, 10, 11, 15, 15, 16, 16, 17, 18]),\n",
       " 'small_group': array([ 4,  3,  1,  3,  4,  1,  4,  3, 18,  2]),\n",
       " 'amount_rur': array([ 4.054, 13.738, 20.701, 21.564, 13.499, 23.722,  4.304,  8.625,\n",
       "        12.938, 28.162]),\n",
       " 'target_bin': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 10 transactions from one record\n",
    "rec = df_data_train[0]\n",
    "{k: v[:10] if type(v) is np.ndarray else v for k, v in rec.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c4723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a902fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a6bfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MemoryMapDataset(df_data_train)\n",
    "dataset_valid = MemoryMapDataset(df_data_train)\n",
    "dataset_test = MemoryMapDataset(df_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25daa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "097ec440",
   "metadata": {},
   "source": [
    "## Build encoder\n",
    "\n",
    "- All parts are available in `ptls.nn`.\n",
    "- You can also use pretrained layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6df2197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc166f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small_group': 201}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check preprocessor dictionary sisez for categoryes\n",
    "preprocessor.get_category_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4ae8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            'small_group': {'in': 150, 'out': 32},\n",
    "        },\n",
    "        numeric_values={\n",
    "            'amount_rur': 'log',\n",
    "        },\n",
    "        embeddings_noise=0.001,\n",
    "    ),\n",
    "    hidden_size=48,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb17f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a332036b",
   "metadata": {},
   "source": [
    "## Choose framework for encoder train\n",
    "\n",
    "- There are both supervised of unsupervised frameworks in `ptls.frames`.\n",
    "- Keep in mind that each framework requires his own batch format.\n",
    "Tools for batch collate can be found in the selected framework package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "494a3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0519c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_module = SequenceToTarget(\n",
    "    seq_encoder=seq_encoder,\n",
    "    head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=4),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy(),\n",
    "    optimizer_partial=partial(torch.optim.Adam),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fb23cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = PtlsDataModule(\n",
    "    train_data=SeqToTargetDataset(dataset_train, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    valid_data=SeqToTargetDataset(dataset_valid, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    test_data=SeqToTargetDataset(dataset_test, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    train_batch_size=128,\n",
    "    valid_batch_size=1024,\n",
    "    train_num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d40c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4474bee",
   "metadata": {},
   "source": [
    "## Train your encoder with selected framework and `pytorch_lightning`\n",
    "\n",
    "- Provide data with one of the DataLoaders that is compatible with selected framework. \n",
    "- Monitor the progress on tensorboard.\n",
    "- Optionally tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "256a9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "841769ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9515cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-90d24705ef40210e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-90d24705ef40210e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e666061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2ba264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a059fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/kireev/pycharm-deploy/pytorch-lifestream/demo/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 16.8 K\n",
      "1 | head          | Head          | 196   \n",
      "2 | loss          | NLLLoss       | 0     \n",
      "3 | train_metrics | ModuleDict    | 0     \n",
      "4 | valid_metrics | ModuleDict    | 0     \n",
      "5 | test_metrics  | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "17.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.0 K    Total params\n",
      "0.068     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 54s, sys: 19.7 s, total: 3min 13s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(sup_module, sup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f71cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(1.2590), 'seq_len': tensor(904.1562), 'val_Accuracy': tensor(0.5374), 'train_Accuracy': tensor(0.5243)}\n"
     ]
    }
   ],
   "source": [
    "# train and validation metrics\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c406d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8c92d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/kireev/pycharm-deploy/pytorch-lifestream/demo/lightning_logs/version_0/checkpoints/epoch=9-step=1570.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /home/kireev/pycharm-deploy/pytorch-lifestream/demo/lightning_logs/version_0/checkpoints/epoch=9-step=1570.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_Accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5798500180244446     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_Accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5798500180244446    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_Accuracy': 0.5798500180244446}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test metrics\n",
    "trainer.test(ckpt_path='best', dataloaders=sup_data.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb1913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88d98090",
   "metadata": {},
   "source": [
    "# Make predict\n",
    "\n",
    "Let's make predict to check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feace140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cf1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e705e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=1000,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0ce98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_module = InferenceModule(\n",
    "    torch.nn.Sequential(\n",
    "        sup_module,\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ),\n",
    "    model_out_name='prob',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad97945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "df_predict = trainer.predict(inf_module, inference_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a8ed81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.concat(df_predict, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29e107a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>target_bin</th>\n",
       "      <th>prob_0000</th>\n",
       "      <th>prob_0001</th>\n",
       "      <th>prob_0002</th>\n",
       "      <th>prob_0003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.861903</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.115479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272358</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>0.686012</td>\n",
       "      <td>0.034851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>0.004783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.826836</td>\n",
       "      <td>0.019963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281833</td>\n",
       "      <td>0.245787</td>\n",
       "      <td>0.076031</td>\n",
       "      <td>0.396349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  target_bin  prob_0000  prob_0001  prob_0002  prob_0003\n",
       "0          6           1   0.017108   0.861903   0.005510   0.115479\n",
       "1          7           0   0.272358   0.006778   0.686012   0.034851\n",
       "2         12           2   0.053981   0.002930   0.938305   0.004783\n",
       "3         13           2   0.149600   0.003601   0.826836   0.019963\n",
       "4         14           0   0.281833   0.245787   0.076031   0.396349"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac486f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18295d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = df_predict[[f'prob_{i:04d}' for i in range(4)]].values.argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fddd3acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df_predict['target_bin'].values\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0447385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82632c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57985"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c94c065e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1908,  327, 1441, 1280],\n",
       "       [ 354, 3360,  128, 1156],\n",
       "       [ 715,   64, 4092,  169],\n",
       "       [1224, 1233,  312, 2237]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37487457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls",
   "language": "python",
   "name": "ptls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
