{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook aims to show the benefits of PTLS models compression using the quantisation techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"\"\n",
    "\n",
    "def estimate_size(model: torch.nn.Module):\n",
    "    const = 1\n",
    "    size = 0\n",
    "    for module in model.parameters():\n",
    "        size += module.numel() * module.element_size()\n",
    "    for buffer in model.buffers():\n",
    "        size += buffer.numel() * buffer.element_size()\n",
    "    return size / const\n",
    "\n",
    "def gain(base, comp):\n",
    "    base, comp = estimate_size(base), estimate_size(comp)\n",
    "    return (base - comp) / base * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aquisition\n",
    "\n",
    "We'll use Age-Group Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, Head\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.preprocessing.pandas.pandas_preprocessor import PandasDataPreprocessor\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/train_target.csv?download=true\"\n",
    ")\n",
    "\n",
    "\n",
    "df_target_train, df_target_test = train_test_split(\n",
    "    df_target, test_size=7000, stratify=df_target[\"bins\"], random_state=142)\n",
    "df_target_train, df_target_valid = train_test_split(\n",
    "    df_target_train, test_size=3000, stratify=df_target_train[\"bins\"], random_state=142)\n",
    "print(\"Split {} records to train: {}, valid: {}, test: {}\".format(\n",
    "    *[\n",
    "      len(df)\n",
    "      for df in [df_target, df_target_train, df_target_valid, df_target_test]\n",
    "    ]\n",
    "))\n",
    "\n",
    "\n",
    "df_trx = pd.read_csv(\n",
    "    \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/transactions_train.csv.gz?download=true\",\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "\n",
    "df_trx_train = pd.merge(df_trx, df_target_train[\"client_id\"], on=\"client_id\", how=\"inner\")\n",
    "df_trx_valid = pd.merge(df_trx, df_target_valid[\"client_id\"], on=\"client_id\", how=\"inner\")\n",
    "df_trx_test = pd.merge(df_trx, df_target_test[\"client_id\"], on=\"client_id\", how=\"inner\")\n",
    "print(\"Split {} transactions to train: {}, valid: {}, test: {}\".format(\n",
    "    *[len(df) for df in [df_trx, df_trx_train, df_trx_valid, df_trx_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"trans_date\",\n",
    "    event_time_transformation=\"none\",\n",
    "    cols_category=[\"small_group\"],\n",
    "    cols_numerical=[\"amount_rur\"],\n",
    "    return_records=False,\n",
    ")\n",
    "df_data_train = preprocessor.fit_transform(df_trx_train)\n",
    "df_data_valid = preprocessor.transform(df_trx_valid)\n",
    "df_data_test = preprocessor.transform(df_trx_test)\n",
    "\n",
    "print(\n",
    "    \"Record in dataset, train {}, valid {}, test {}\".format(\n",
    "        *[len(df) for df in [df_data_train, df_data_valid, df_data_test]]\n",
    "    )\n",
    ")\n",
    "print(\"Each record is a client with list of transactions\")\n",
    "\n",
    "df_target = df_target.rename(columns={\"bins\": \"target_bin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.merge(df_data_train, df_target, on=\"client_id\")\n",
    "df_data_valid = pd.merge(df_data_valid, df_target, on=\"client_id\")\n",
    "df_data_test = pd.merge(df_data_test, df_target, on=\"client_id\")\n",
    "\n",
    "df_data_train = df_data_train.to_dict(orient=\"records\")\n",
    "df_data_valid = df_data_valid.to_dict(orient=\"records\")\n",
    "df_data_test = df_data_test.to_dict(orient=\"records\")\n",
    "\n",
    "dataset_train = MemoryMapDataset(df_data_train)\n",
    "dataset_valid = MemoryMapDataset(df_data_valid)\n",
    "dataset_test = MemoryMapDataset(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "sup_data : LightningDataModule = PtlsDataModule(\n",
    "    train_data=SeqToTargetDataset(dataset_train, target_col_name=\"target_bin\", target_dtype=torch.long),\n",
    "    valid_data=SeqToTargetDataset(dataset_valid, target_col_name=\"target_bin\", target_dtype=torch.long),\n",
    "    test_data=SeqToTargetDataset(dataset_test, target_col_name=\"target_bin\", target_dtype=torch.long),\n",
    "    train_batch_size=128,\n",
    "    valid_batch_size=1024,\n",
    "    train_num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example batch may be useful for model structure evaluation \n",
    "\n",
    "example_batch_coles = next(iter(sup_data.train_dataloader()))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            \"small_group\": {\"in\": 150, \"out\": 32},\n",
    "        },\n",
    "        numeric_values={\n",
    "            \"amount_rur\": \"log\",\n",
    "        },\n",
    "        embeddings_noise=0.001,\n",
    "    ),\n",
    "    hidden_size=48,\n",
    "    type='lstm'\n",
    ")\n",
    "\n",
    "sup_module = SequenceToTarget(\n",
    "    seq_encoder=seq_encoder,\n",
    "    head=Head(input_size=seq_encoder.embedding_size, objective=\"classification\", num_classes=4),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy(task=\"multiclass\", num_classes=4),\n",
    "    optimizer_partial=partial(torch.optim.Adam),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.nn import TrxEncoder, TransformerSeqEncoder, Head\n",
    "\n",
    "trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            'small_group': {'in': 150, 'out': 31},\n",
    "        },\n",
    "        numeric_values={\n",
    "            'amount_rur': 'log',\n",
    "        },\n",
    "        embeddings_noise=0.001\n",
    ")\n",
    "\n",
    "trx_encoder.output_size\n",
    "\n",
    "transformer_params = {\n",
    "    \"n_heads\": 1,\n",
    "    \"dim_hidden\": 128,\n",
    "    \"n_layers\": 4,\n",
    "}\n",
    "\n",
    "seq_encoder = TransformerSeqEncoder(\n",
    "    trx_encoder=trx_encoder,\n",
    "    **transformer_params\n",
    ")\n",
    "\n",
    "transformer_module = SequenceToTarget(\n",
    "    seq_encoder=seq_encoder,\n",
    "    head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=4),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy('multiclass', num_classes=4),\n",
    "    optimizer_partial=partial(torch.optim.Adam),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressor run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.fedcore_compression import (\n",
    "    PTQ_1 as experimental_setup_dynamic, \n",
    "    fedcore_fit, \n",
    "    eval_computational_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedcore_compressor_rnn = fedcore_fit(sup_module, sup_data, experimental_setup_dynamic, n_cls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedcore_compressor_transformer = fedcore_fit(transformer_module, sup_data, experimental_setup_dynamic, n_cls=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computational_eval(fedcore_compressor, sup_data):\n",
    "    computational_results = {}\n",
    "    computational_results['optimised'] = eval_computational_metrics(\n",
    "        fedcore_compressor.optimised_model,\n",
    "        sup_data.test_dataloader(),\n",
    "        'computational.txt',\n",
    "        id='optimised',\n",
    "        n_batches=1,\n",
    "        device=torch.device('cpu')\n",
    "    )\n",
    "    computational_results['original'] = eval_computational_metrics(\n",
    "        fedcore_compressor.original_model,\n",
    "        sup_data.test_dataloader(),\n",
    "        'computational.txt',\n",
    "        id='original',\n",
    "        n_batches=1,\n",
    "        device=torch.device('cpu')\n",
    "    )\n",
    "    return computational_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN-based Model\n",
    "rnn_computational = computational_eval(fedcore_compressor_rnn, sup_data)\n",
    "\n",
    "# Transformer-based Model\n",
    "transformer_computational = computational_eval(fedcore_compressor_transformer, sup_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_eval(fedcore_compressor, sup_data):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        accelerator=\"cpu\",\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    quality_metrics = {}\n",
    "    quality_metrics['original'] = trainer.test(fedcore_compressor.original_model, dataloaders=sup_data.test_dataloader())\n",
    "    quality_metrics['optimised'] = trainer.test(fedcore_compressor.optimised, dataloaders=sup_data.test_dataloader())\n",
    "    return quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN-based model\n",
    "rnn_quality = quality_eval(fedcore_compressor_rnn, sup_data)\n",
    "\n",
    "# Transformer-based model\n",
    "transformer_quality = quality_eval(fedcore_compressor_transformer, sup_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls-experiments-H-SwwRmK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
