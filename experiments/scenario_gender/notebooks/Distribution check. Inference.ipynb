{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = 1e-7\n",
    "\n",
    "# prediction = (torch.tensor([[np.log(10 + 1)]]), \n",
    "#               torch.tensor([[100., 0., 0., 0., 0., 0.]]),\n",
    "#               torch.tensor([[0]]),\n",
    "#               torch.tensor([[0., 100., 0., 0., 0., 0.]]))\n",
    "\n",
    "# label = np.array([[10,\n",
    "#                    list([1., 0., 0., 0., 0., 0.]),\n",
    "#                    0,\n",
    "#                    list([0., 1., 0., 0., 0., 0.])]])\n",
    "\n",
    "# loss = DistributionTargetsLoss()\n",
    "# out = loss(prediction, label)\n",
    "# assert abs(out.item() - 0.) < eps\n",
    "# assert type(out) is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b2ad50f791a1>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[-1.,\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-7\n",
    "\n",
    "params = {'head_layers':\n",
    "             {'CombinedTargetHeadFromRnn':\n",
    "                 {'in_size': 48,\n",
    "                  'num_distr_classes': 6,\n",
    "                  'pos': True,\n",
    "                  'neg': True,\n",
    "                  'use_gates': True,\n",
    "                  'pass_samples': True\n",
    "                 }\n",
    "             }\n",
    "         }\n",
    "\n",
    "prediction = (torch.tensor([[-1.]]), \n",
    "              torch.tensor([[1., 0., 0., 0., 0., 0.]]),\n",
    "              torch.tensor([[ 1.]]),\n",
    "              torch.tensor([[0., 1., 0., 0., 0., 0.]]))\n",
    "\n",
    "label = np.array([[-1.,\n",
    "                   list([1., 0., 0., 0., 0., 0.]),\n",
    "                   1.,\n",
    "                   list([0., 1., 0., 0., 0., 0.])]])\n",
    "\n",
    "loss = DistributionTargetsLoss(params)\n",
    "out = loss(prediction, label)\n",
    "\n",
    "assert abs(out.item() - 10.703149795532227) < eps\n",
    "assert type(out) is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dltranz.loss import DistributionTargetsLoss\n",
    "\n",
    "\n",
    "def test_best_loss():\n",
    "    eps = 1e-7\n",
    "    params = {'head_layers':\n",
    "                 {'CombinedTargetHeadFromRnn':\n",
    "                     {'in_size': 48,\n",
    "                      'num_distr_classes': 6,\n",
    "                      'pos': True,\n",
    "                      'neg': True,\n",
    "                      'use_gates': True,\n",
    "                      'pass_samples': True\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    prediction = (torch.tensor([[np.log(10 + 1)]]), \n",
    "                  torch.tensor([[100., 0., 0., 0., 0., 0.]]),\n",
    "                  torch.tensor([[0]]),\n",
    "                  torch.tensor([[0., 100., 0., 0., 0., 0.]]))\n",
    "\n",
    "    label = np.array([[10,\n",
    "                       list([1., 0., 0., 0., 0., 0.]),\n",
    "                       0,\n",
    "                       list([0., 1., 0., 0., 0., 0.])]])\n",
    "\n",
    "    loss = DistributionTargetsLoss(params)\n",
    "    out = loss(prediction, label)\n",
    "    assert abs(out.item() - 0.) < eps\n",
    "    assert type(out) is torch.Tensor\n",
    "\n",
    "\n",
    "def test_loss_300():\n",
    "    eps = 1e-7\n",
    "    params = {'head_layers':\n",
    "                 {'CombinedTargetHeadFromRnn':\n",
    "                     {'in_size': 48,\n",
    "                      'num_distr_classes': 6,\n",
    "                      'pos': True,\n",
    "                      'neg': True,\n",
    "                      'use_gates': True,\n",
    "                      'pass_samples': True\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    prediction = (torch.tensor([[10]]), \n",
    "                  torch.tensor([[100., 0., 0., 0., 0., 0.]]),\n",
    "                  torch.tensor([[0]]),\n",
    "                  torch.tensor([[0., 100., 0., 0., 0., 0.]]))\n",
    "\n",
    "    label = np.array([[0,\n",
    "                       list([1., 0., 0., 0., 0., 0.]),\n",
    "                       0,\n",
    "                       list([0., 1., 0., 0., 0., 0.])]])\n",
    "\n",
    "    loss = DistributionTargetsLoss(params)\n",
    "    out = loss(prediction, label)\n",
    "    assert abs(out.item() - 300.) < eps\n",
    "    assert type(out) is torch.Tensor\n",
    "\n",
    "    \n",
    "def test_usual_loss_first():\n",
    "    eps = 1e-7\n",
    "    params = {'head_layers':\n",
    "                 {'CombinedTargetHeadFromRnn':\n",
    "                     {'in_size': 48,\n",
    "                      'num_distr_classes': 6,\n",
    "                      'pos': True,\n",
    "                      'neg': True,\n",
    "                      'use_gates': True,\n",
    "                      'pass_samples': True\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    prediction = (torch.tensor([[-1.]]), \n",
    "                  torch.tensor([[0.1, 0.2, 0.1, 0.1, 0.3, 0.2]]),\n",
    "                  torch.tensor([[ 1.]]),\n",
    "                  torch.tensor([[0.1, 0.2, 0.1, 0.1, 0.3, 0.2]]))\n",
    "\n",
    "    label = np.array([[-1.,\n",
    "                       list([0.1, 0.2, 0.1, 0.1, 0.3, 0.2]),\n",
    "                       1.,\n",
    "                       list([0.1, 0.2, 0.1, 0.1, 0.3, 0.2])]])\n",
    "\n",
    "    loss = DistributionTargetsLoss(params)\n",
    "    out = loss(prediction, label)\n",
    "\n",
    "    assert abs(out.item() - 12.138458251953125) < eps\n",
    "    assert type(out) is torch.Tensor\n",
    "\n",
    "\n",
    "def test_usual_loss_second():\n",
    "    eps = 1e-7\n",
    "    params = {'head_layers':\n",
    "                 {'CombinedTargetHeadFromRnn':\n",
    "                     {'in_size': 48,\n",
    "                      'num_distr_classes': 6,\n",
    "                      'pos': True,\n",
    "                      'neg': True,\n",
    "                      'use_gates': True,\n",
    "                      'pass_samples': True\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    prediction = (torch.tensor([[-1.]]), \n",
    "                  torch.tensor([[0.1, 0.2, 0.1, 0.1, 0.3, 0.2]]),\n",
    "                  torch.tensor([[ 1.]]),\n",
    "                  torch.tensor([[0.3, 0.5, 0., 0.1, 0.1, 0.0]]))\n",
    "\n",
    "    label = np.array([[-10.,\n",
    "                       list([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]),\n",
    "                       8.,\n",
    "                       list([0.1, 0.1, 0.1, 0.1, 0.1, 0.5])]])\n",
    "\n",
    "    loss = DistributionTargetsLoss(params)\n",
    "    out = loss(prediction, label)\n",
    "\n",
    "    assert abs(out.item() - 38.563011169433594) < eps\n",
    "    assert type(out) is torch.Tensor\n",
    "\n",
    "    \n",
    "def test_one_class():\n",
    "    eps = 1e-7\n",
    "    params = {'head_layers':\n",
    "                 {'CombinedTargetHeadFromRnn':\n",
    "                     {'in_size': 48,\n",
    "                      'num_distr_classes': 6,\n",
    "                      'pos': True,\n",
    "                      'neg': True,\n",
    "                      'use_gates': True,\n",
    "                      'pass_samples': True\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    prediction = (torch.tensor([[-1.]]), \n",
    "                  torch.tensor([[1., 0., 0., 0., 0., 0.]]),\n",
    "                  torch.tensor([[ 1.]]),\n",
    "                  torch.tensor([[0., 1., 0., 0., 0., 0.]]))\n",
    "\n",
    "    label = np.array([[-1.,\n",
    "                       list([1., 0., 0., 0., 0., 0.]),\n",
    "                       1.,\n",
    "                       list([0., 1., 0., 0., 0., 0.])]])\n",
    "\n",
    "    loss = DistributionTargetsLoss(params)\n",
    "    out = loss(prediction, label)\n",
    "\n",
    "    assert abs(out.item() - 10.703149795532227) < eps\n",
    "    assert type(out) is torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f2fb864f172a>:142: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[-1.,\n",
      "<ipython-input-7-f2fb864f172a>:112: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[-10.,\n",
      "<ipython-input-7-f2fb864f172a>:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[-1.,\n",
      "<ipython-input-7-f2fb864f172a>:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[0,\n",
      "<ipython-input-7-f2fb864f172a>:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  label = np.array([[10,\n"
     ]
    }
   ],
   "source": [
    "test_one_class()\n",
    "test_usual_loss_second()\n",
    "test_usual_loss_first()\n",
    "test_loss_300()\n",
    "test_best_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.custom_layers import DropoutEncoder, Squeeze, CatLayer, MLP, TabularRowEncoder, CombinedTargetHeadFromRnn\n",
    "distr_target_head_config = {\n",
    "    \"in_size\": 48,\n",
    "    \"num_distr_classes\": 6\n",
    "}\n",
    "\n",
    "distr_target_head = CombinedTargetHeadFromRnn(**distr_target_head_config)\n",
    "x = torch.rand(64, 48)\n",
    "x = (x, np.ones((64,)), np.ones((64,)))\n",
    "y = distr_target_head(x)\n",
    "assert type(y) == tuple and len(y) == 4\n",
    "assert y[0].shape == y[2].shape == (64, 1) and y[1].shape == y[3].shape == (64, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dltranz.trx_encoder import PaddedBatch\n",
    "from dltranz.seq_encoder.rnn_encoder import RnnSeqEncoderDistributionTarget\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    payload = {'amount': torch.arange(4*10).view(4, 10).float(),\n",
    "               'event_time': torch.arange(4*10).view(4, 10).float(),\n",
    "               'mcc_code': torch.arange(4*10).view(4, 10),\n",
    "               'tr_type': torch.arange(4*10).view(4, 10)\n",
    "              }\n",
    "    return PaddedBatch(\n",
    "                       payload=payload,\n",
    "                       length=torch.tensor([4, 2, 6, 8])\n",
    "                      )\n",
    "\n",
    "\n",
    "def test_shape():\n",
    "    eps = 1e-5\n",
    "    \n",
    "    params = {\n",
    "        'trx_encoder' : {\n",
    "            'norm_embeddings': False,\n",
    "            'embeddings_noise': 0.003,\n",
    "            'embeddings': {\n",
    "                'mcc_code': {\n",
    "                    'in': 200,\n",
    "                    'out': 48\n",
    "                },\n",
    "                'tr_type': {\n",
    "                    'in': 100,\n",
    "                    'out': 24\n",
    "                }\n",
    "            },\n",
    "            'numeric_values': {\n",
    "                'amount': 'identity'\n",
    "            },\n",
    "        },\n",
    "        'rnn': {\n",
    "            'hidden_size': 48,\n",
    "            'type': 'gru',\n",
    "            'bidir': False,\n",
    "            'trainable_starter': 'static',\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    model = RnnSeqEncoderDistributionTarget(params, True)\n",
    "\n",
    "    x = get_data()\n",
    "\n",
    "    out = model(x)\n",
    "    assert type(out) == tuple and len(out) == 3\n",
    "    assert type(out[0]) == torch.Tensor and out[0].shape == torch.Size([4, 48])\n",
    "    assert (out[1] - np.array([-16.118095, -16.118095, -16.118095, -16.118095]) < np.zeros((1, 4)) + eps).all()\n",
    "    assert (out[2] - np.array([3.302955, 11.313237, 25.456194, 37.45834])< np.zeros((1, 4)) + eps).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dltranz.trx_encoder import PaddedBatch\n",
    "from dltranz.seq_encoder.rnn_encoder import RnnSeqEncoder\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    payload = {'amount': torch.arange(4*10).view(4, 10).float(),\n",
    "               'event_time': torch.arange(4*10).view(4, 10).float(),\n",
    "               'mcc_code': torch.arange(4*10).view(4, 10),\n",
    "               'tr_type': torch.arange(4*10).view(4, 10)\n",
    "              }\n",
    "    return PaddedBatch(\n",
    "                       payload=payload,\n",
    "                       length=torch.tensor([4, 2, 6, 8])\n",
    "                      )\n",
    "\n",
    "def test_shape():\n",
    "    eps = 1e-5\n",
    "    \n",
    "    params = {\n",
    "        'trx_encoder' : {\n",
    "            'norm_embeddings': False,\n",
    "            'embeddings_noise': 0.003,\n",
    "            'embeddings': {\n",
    "                'mcc_code': {\n",
    "                    'in': 200,\n",
    "                    'out': 48\n",
    "                },\n",
    "                'tr_type': {\n",
    "                    'in': 100,\n",
    "                    'out': 24\n",
    "                }\n",
    "            },\n",
    "            'numeric_values': {\n",
    "                'amount': 'identity'\n",
    "            },\n",
    "        },\n",
    "        'rnn': {\n",
    "            'hidden_size': 48,\n",
    "            'type': 'gru',\n",
    "            'bidir': False,\n",
    "            'trainable_starter': 'static'\n",
    "        },\n",
    "        'head_layers': {\n",
    "            'CombinedTargetHeadFromRnn': {\n",
    "                'in_size': 48,\n",
    "                'num_distr_classes': 6,\n",
    "                'pos': True,\n",
    "                'neg': True,\n",
    "                'use_gates': True,\n",
    "                'pass_samples': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    model = RnnSeqEncoder(params, True)\n",
    "\n",
    "    x = get_data()\n",
    "\n",
    "    out = model(x)\n",
    "    assert type(out) == torch.Tensor and out.shape == torch.Size([4, 48])\n",
    "    assert type(out[0]) == torch.Tensor and out.shape == torch.Size([4, 48])\n",
    "\n",
    "test_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dltranz.trx_encoder import PaddedBatch\n",
    "from dltranz.seq_encoder.statistics_encoder import StatisticsEncoder\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    payload = {'amount': torch.arange(4*10).view(4, 10).float(),\n",
    "               'event_time': torch.arange(4*10).view(4, 10).float(),\n",
    "               'mcc_code': torch.arange(4*10).view(4, 10),\n",
    "               'tr_type': torch.arange(4*10).view(4, 10)\n",
    "              }\n",
    "    return PaddedBatch(\n",
    "                       payload=payload,\n",
    "                       length=torch.tensor([4, 2, 6, 8])\n",
    "                      )\n",
    "\n",
    "def test_shape():\n",
    "    eps = 1e-4\n",
    "\n",
    "    model = StatisticsEncoder({})\n",
    "\n",
    "    x = get_data()\n",
    "\n",
    "    out = model(x)\n",
    "    assert isinstance(out, tuple) and len(out) == 4\n",
    "    \n",
    "    assert (abs(out[0] -  torch.Tensor([[-16.1181],\n",
    "                                        [-16.1181],\n",
    "                                        [-16.1181],\n",
    "                                        [-16.1181]])) < torch.zeros((4, 1)) + eps).all()\n",
    "    assert out[1].shape == torch.Size([4, 6]) and out[1][0][3] == 0 and out[1][3][1] == 0\n",
    "    assert out[2].shape == torch.Size([4, 1]) and abs(out[2][0].item() - 3.3029549820009882) < eps\n",
    "    assert out[3].shape == torch.Size([4, 6]) and abs(out[3][1][3].item() - 0.7310606456724159) < eps\n",
    "\n",
    "test_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_negative_trx': array([2010, 2370, 1010, 1110, 2330, 2371, 2011, 2020, 2331, 1100, 1030,\n",
       "        1200, 1210, 2210, 2021, 2110, 2340, 2440, 2460, 2320, 4010, 4071,\n",
       "        2341, 2456, 4051, 1310, 1410, 4110, 2100, 2200, 4011, 1000, 4210,\n",
       "        2446, 1510, 4020, 4500, 4041, 4090, 4031, 4021, 4097, 4100, 4061,\n",
       "        2000, 4200, 4096, 4045, 4035]),\n",
       " 'top_positive_trx': array([2010, 2370, 1010, 1110, 2330, 2371, 2011, 2020, 2331, 1100, 1030,\n",
       "        1200, 1210, 2210, 2021, 2110, 2340, 2440, 2460, 2320, 4010, 4071,\n",
       "        2341, 2456, 4051, 1310, 1410, 4110, 2100, 2200, 4011, 1000, 4210,\n",
       "        2446, 1510, 4020, 4500, 4041, 4090, 4031, 4021, 4097, 4100, 4061,\n",
       "        2000, 4200, 4096, 4045, 4035])}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = ('top_negative_trx', np.array([2010, 2370, 1010, 1110, 2330, 2371, 2011, 2020, 2331, 1100, 1030, \n",
    "                                         1200, 1210, 2210, 2021, 2110, 2340, 2440, 2460, 2320, 4010, 4071,\n",
    "                                         2341, 2456, 4051, 1310, 1410, 4110, 2100, 2200, 4011, 1000, 4210,\n",
    "                                         2446, 1510, 4020, 4500, 4041, 4090, 4031, 4021, 4097, 4100, 4061,\n",
    "                                         2000, 4200, 4096, 4045, 4035]))\n",
    "pos = ('top_positive_trx', np.array([2010, 2370, 1010, 1110, 2330, 2371, 2011, 2020, 2331, 1100, 1030, \n",
    "                                         1200, 1210, 2210, 2021, 2110, 2340, 2440, 2460, 2320, 4010, 4071,\n",
    "                                         2341, 2456, 4051, 1310, 1410, 4110, 2100, 2200, 4011, 1000, 4210,\n",
    "                                         2446, 1510, 4020, 4500, 4041, 4090, 4031, 4021, 4097, 4100, 4061,\n",
    "                                         2000, 4200, 4096, 4045, 4035]))\n",
    "\n",
    "dict([neg, pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dltranz.custom_layers import DropoutEncoder, Squeeze, CatLayer, MLP, TabularRowEncoder, DistributionTargetsHead\n",
    "\n",
    "\n",
    "class DistributionTargetsHeadTest(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_distribution_target_head():\n",
    "    distr_target_head_config = {\n",
    "        \"in_size\": 48,\n",
    "        \"num_distr_classes\": 6\n",
    "    }\n",
    "    \n",
    "    distr_target_head = DistributionTargetsHead(**distr_target_head_config)\n",
    "    x = torch.rand(64, 48)\n",
    "    y = distr_target_head(x)\n",
    "    assert type(y) == tuple and len(y) == 4\n",
    "    assert y[0].shape == y[2].shape == (64, 1) and y[1].shape == y[3].shape == (64, 6)\n",
    "    \n",
    "\n",
    "\n",
    "class TrxEncoderTest(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_dropout_encoder():\n",
    "    drop_encoder = DropoutEncoder(p=0.5)\n",
    "    x = torch.rand(256, 100)\n",
    "\n",
    "    drop_encoder.eval()\n",
    "    assert torch.equal(x, drop_encoder(x))\n",
    "\n",
    "    drop_encoder.train()\n",
    "    assert x.shape == drop_encoder(x).shape\n",
    "\n",
    "\n",
    "def test_squeeze():\n",
    "    x = torch.rand(256, 100, 1)\n",
    "    squeeze = Squeeze()\n",
    "    y = squeeze(x)\n",
    "    assert y.shape == (256, 100)\n",
    "\n",
    "\n",
    "def test_mlp():\n",
    "    mlp_config = {\n",
    "        \"hidden_layers_size\": [512, 100],\n",
    "        \"drop_p\": 0.5,\n",
    "        \"objective\": \"classification\"\n",
    "    }\n",
    "\n",
    "    mlp = MLP(512, mlp_config)\n",
    "    x = torch.rand(256, 512)\n",
    "    y = mlp(x)\n",
    "    assert y.shape == (256,)\n",
    "\n",
    "\n",
    "def test_cat_layer():\n",
    "    left_tail = torch.nn.Linear(100, 10)\n",
    "    right_tail = torch.nn.Linear(200, 20)\n",
    "\n",
    "    cat_layer = CatLayer(left_tail, right_tail)\n",
    "    l = torch.rand(256, 100)\n",
    "    r = torch.rand(256, 200)\n",
    "    x = (l, r)\n",
    "    y = cat_layer(x)\n",
    "    assert y.shape == (256, 30)\n",
    "\n",
    "\n",
    "def test_embedding_generator():\n",
    "    tabular_config = {\n",
    "        'num_features_count': 10,\n",
    "        'cat_features_dims': [10, 10],\n",
    "        'cat_emb_dim': 4\n",
    "    }\n",
    "\n",
    "    tabular_row_encoder = TabularRowEncoder(\n",
    "        input_dim=tabular_config['num_features_count'] + len(tabular_config['cat_features_dims']),\n",
    "        cat_dims=tabular_config['cat_features_dims'],\n",
    "        cat_idxs=[x + tabular_config['num_features_count'] for x in range(len(tabular_config['cat_features_dims']))],\n",
    "        cat_emb_dim=tabular_config['cat_emb_dim']\n",
    "    )\n",
    "\n",
    "    assert tabular_row_encoder.output_size == 18\n",
    "\n",
    "    num = torch.rand(256, 10)\n",
    "    cat = torch.randint(0, 10, (256, 2))\n",
    "    x = torch.cat([num, cat], dim=1)\n",
    "    y = tabular_row_encoder(x)\n",
    "\n",
    "    assert y.shape == (256, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import ChainDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from dltranz.data_load import IterableChain, padded_collate, IterableAugmentations\n",
    "from dltranz.data_load.augmentations.seq_len_limit import SeqLenLimit\n",
    "from dltranz.data_load.iterable_processing.category_size_clip import CategorySizeClip\n",
    "from dltranz.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from dltranz.data_load.iterable_processing.target_extractor import TargetExtractor\n",
    "from dltranz.data_load.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from dltranz.metric_learn.inference_tools import save_scores\n",
    "from dltranz.train import score_model2\n",
    "from dltranz.util import get_conf, get_cls\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from ignite.contrib.handlers import ProgressBar, LRScheduler, create_lr_scheduler_with_warmup\n",
    "from ignite.contrib.handlers.param_scheduler import ParamScheduler\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import RunningAverage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "\n",
    "warnings.filterwarnings('ignore', module='tensorboard.compat.tensorflow_stub.dtypes')\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dltranz.trx_encoder import PaddedBatch\n",
    "from dltranz.swa import SWA\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "import ignite\n",
    "from bisect import bisect_right\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('my_config_for_jupyter.pickle', 'rb') as handle:\n",
    "    conf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf['inference_dataloader']['loader']['batch_size'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('my_config_for_jupyter_model.pickle', 'rb') as handle:\n",
    "    conf_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Distribution check. Inference..ipynb'\t models\r\n",
      " README.md\t\t\t\t my_config_for_jupyter.pickle\r\n",
      " bin\t\t\t\t\t my_config_for_jupyter_model.pickle\r\n",
      " conf\t\t\t\t\t notebooks\r\n",
      " data\t\t\t\t\t results\r\n",
      " distribution_targets.py\t\t scenario_gender\r\n",
      " lightning_logs\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_dataloader(conf, pl_module):\n",
    "    \"\"\"This is inference dataloader for `experiments`\n",
    "    \"\"\"\n",
    "    post_processing = IterableChain(\n",
    "        TargetExtractor(target_col=conf['col_id']),\n",
    "        FeatureFilter(keep_feature_names=pl_module.seq_encoder.category_names),\n",
    "        CategorySizeClip(pl_module.seq_encoder.category_max_size),\n",
    "        IterableAugmentations(\n",
    "            SeqLenLimit(**conf['SeqLenLimit']),\n",
    "        )\n",
    "    )\n",
    "    l_dataset = [\n",
    "        ParquetDataset(\n",
    "            ParquetFiles(path).data_files,\n",
    "            post_processing=post_processing,\n",
    "            shuffle_files=False,\n",
    "        ) for path in conf['dataset_files']]\n",
    "    dataset = ChainDataset(l_dataset)\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        collate_fn=padded_collate,\n",
    "        shuffle=False,\n",
    "        num_workers=conf['loader.num_workers'],\n",
    "        batch_size=conf['loader.batch_size'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltranz.seq_cls import SequenceClassify\n",
    "\n",
    "\n",
    "model = SequenceClassify(conf_model['params'], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl_module = get_cls(conf['params.pl_module_class'])\n",
    "# model = pl_module(conf['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = create_inference_dataloader(conf['inference_dataloader'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "                  \r"
     ]
    }
   ],
   "source": [
    "if 'seed_everything' in conf:\n",
    "    pl.seed_everything(conf['seed_everything'])\n",
    "\n",
    "pl_module = get_cls(conf['params.pl_module_class'])\n",
    "\n",
    "model = pl_module(conf['params'])\n",
    "# if conf.get('random_model', False):\n",
    "#     model = pl_module(conf['params'])\n",
    "# else:\n",
    "#     model = pl_module.load_from_checkpoint(conf['model_path'])\n",
    "# model.seq_encoder.is_reduce_sequence = True\n",
    "\n",
    "dl = create_inference_dataloader(conf['inference_dataloader'], model)\n",
    "\n",
    "pred, ids = score_model2(model, dl, conf['params'])\n",
    "\n",
    "df_scores_cols = [f'v{i:003d}' for i in range(pred.shape[1])]\n",
    "col_id = conf['inference_dataloader.col_id']\n",
    "df_scores = pd.concat([\n",
    "    pd.DataFrame({col_id: ids}),\n",
    "    pd.DataFrame(pred, columns=df_scores_cols),\n",
    "    ], axis=1)\n",
    "# logger.info(f'df_scores examples: {df_scores.shape}:')\n",
    "\n",
    "# save_scores(df_scores, None, conf['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1170])\n",
      "tensor(1170, dtype=torch.int32)\n",
      "(1,)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in tqdm(dl, leave=False):\n",
    "        x, *others = batch\n",
    "        print(x.payload['amount'].shape)\n",
    "        print(torch.max(x.seq_lens))\n",
    "        print(others[0].shape)\n",
    "\n",
    "        x = x.to('cuda:0')\n",
    "        out = model(x)\n",
    "        print(out.shape)\n",
    "        break\n",
    "\n",
    "        batch_output = [out.cpu().numpy(), *others]\n",
    "        outputs.append(batch_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10915793'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-13855.776 ,  -5865.934 ,   2668.8064,   1957.0739,   5359.918 ,\n",
       "         -7469.6885]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Distribution targets.ipynb'\t\t    test_trx.parquet\r\n",
      " agg_feat_embed.pickle\t\t\t    tr_mcc_codes.csv\r\n",
      " gender_test_kaggle_sample_submission.csv   tr_types.csv\r\n",
      " gender_train.csv\t\t\t    train_trx.parquet\r\n",
      " gender_train_distribution_gt.csv\t    trans-gender-2019.zip\r\n",
      " gender_train_distribution_target.csv\t    transactions.csv\r\n",
      " test_ids.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10058778</td>\n",
       "      <td>(-23111070.490000006, [0.0100318209016029, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10230827</td>\n",
       "      <td>(-2924061.3000000017, [0.029598155141275586, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10280886</td>\n",
       "      <td>(-4927824.540000005, [0.11142153409544886, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11681378</td>\n",
       "      <td>(-7984107.140000006, [0.27103410087755886, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12051455</td>\n",
       "      <td>(-15816769.950000003, [0.1532716299006423, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>80961223</td>\n",
       "      <td>(-9835408.080000006, [0.09336043228010113, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13638</th>\n",
       "      <td>81846240</td>\n",
       "      <td>(-6292680.730000001, [0.19184777550282606, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13639</th>\n",
       "      <td>88536358</td>\n",
       "      <td>(-4745959.820000001, [0.10899479970734352, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>89157170</td>\n",
       "      <td>(-4977460.249999999, [0.007674305384960133, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13641</th>\n",
       "      <td>96649358</td>\n",
       "      <td>(-5878521.980000007, [0.19049733314087203, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id                                             gender\n",
       "0         10058778  (-23111070.490000006, [0.0100318209016029, 0.4...\n",
       "1         10230827  (-2924061.3000000017, [0.029598155141275586, 0...\n",
       "2         10280886  (-4927824.540000005, [0.11142153409544886, 0.7...\n",
       "3         11681378  (-7984107.140000006, [0.27103410087755886, 0.5...\n",
       "4         12051455  (-15816769.950000003, [0.1532716299006423, 0.5...\n",
       "...            ...                                                ...\n",
       "13637     80961223  (-9835408.080000006, [0.09336043228010113, 0.6...\n",
       "13638     81846240  (-6292680.730000001, [0.19184777550282606, 0.3...\n",
       "13639     88536358  (-4745959.820000001, [0.10899479970734352, 0.5...\n",
       "13640     89157170  (-4977460.249999999, [0.007674305384960133, 0....\n",
       "13641     96649358  (-5878521.980000007, [0.19049733314087203, 0.3...\n",
       "\n",
       "[13642 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv('data/gender_train_distribution_gt.csv')\n",
    "df_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10058778</td>\n",
       "      <td>(-11411767.080000004, [0.014152865096857542, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10230827</td>\n",
       "      <td>(-3245337.660000001, [0.05784240645085909, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10280886</td>\n",
       "      <td>(-2338431.8499999996, [0.038333907400380327, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11681378</td>\n",
       "      <td>(-8399862.260000015, [0.36679991345477087, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12051455</td>\n",
       "      <td>(-8028976.4, [0.3203062385387009, 0.3692387002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>80961223</td>\n",
       "      <td>(-6731554.2, [0.08209258866251128, 0.649263449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13638</th>\n",
       "      <td>81846240</td>\n",
       "      <td>(-6774924.700000001, [0.13851338303435304, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13639</th>\n",
       "      <td>88536358</td>\n",
       "      <td>(-2869008.3, [0.06540160235855713, 0.492393486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>89157170</td>\n",
       "      <td>(-4320156.710000003, [0.03691662842480543, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13641</th>\n",
       "      <td>96649358</td>\n",
       "      <td>(-4709228.400000008, [0.1320650300163821, 0.23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id                                             gender\n",
       "0         10058778  (-11411767.080000004, [0.014152865096857542, 0...\n",
       "1         10230827  (-3245337.660000001, [0.05784240645085909, 0.8...\n",
       "2         10280886  (-2338431.8499999996, [0.038333907400380327, 0...\n",
       "3         11681378  (-8399862.260000015, [0.36679991345477087, 0.4...\n",
       "4         12051455  (-8028976.4, [0.3203062385387009, 0.3692387002...\n",
       "...            ...                                                ...\n",
       "13637     80961223  (-6731554.2, [0.08209258866251128, 0.649263449...\n",
       "13638     81846240  (-6774924.700000001, [0.13851338303435304, 0.4...\n",
       "13639     88536358  (-2869008.3, [0.06540160235855713, 0.492393486...\n",
       "13640     89157170  (-4320156.710000003, [0.03691662842480543, 0.7...\n",
       "13641     96649358  (-4709228.400000008, [0.1320650300163821, 0.23...\n",
       "\n",
       "[13642 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv('data/gender_train_distribution_new_target.csv')\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_gt = []\n",
    "l_target = []\n",
    "\n",
    "for row in df_gt['gender']:\n",
    "    l_gt += [ast.literal_eval(row)]\n",
    "for row in df_target['gender']:\n",
    "    l_target += [ast.literal_eval(row)]\n",
    "    \n",
    "gt_neg_distr = np.array(l_gt, dtype=object)[:, 1]\n",
    "target_neg_distr = np.array(l_target, dtype=object)[:, 1]\n",
    "\n",
    "out_gt = []\n",
    "out_target = []\n",
    "for i in range(len(gt_neg_distr)):\n",
    "    out_gt += [list(gt_neg_distr[i])]\n",
    "for i in range(len(target_neg_distr)):\n",
    "    out_target += [list(target_neg_distr[i])]\n",
    "out_gt = torch.tensor(np.array(out_gt))\n",
    "out_target = torch.tensor(np.array(out_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13642, 6])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13642, 6])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07],\n",
       "       [1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07],\n",
       "       [1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07],\n",
       "       ...,\n",
       "       [1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07],\n",
       "       [1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07],\n",
       "       [1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07, 1.e-07]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = np.zeros(out_gt.shape)\n",
    "eps + 0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0884, 0.2174, 0.2524, 0.2136, 0.2198, 0.0083],\n",
       "        [0.1895, 0.1455, 0.2113, 0.0395, 0.1995, 0.2147],\n",
       "        [0.1640, 0.0530, 0.1676, 0.2352, 0.2114, 0.1688],\n",
       "        ...,\n",
       "        [0.0272, 0.0872, 0.1427, 0.2363, 0.2255, 0.2811],\n",
       "        [0.0324, 0.0805, 0.2417, 0.2206, 0.2287, 0.1961],\n",
       "        [0.0115, 0.0545, 0.1542, 0.2670, 0.2859, 0.2269]], dtype=torch.float64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = np.random.random(out_gt.shape)\n",
    "rand = torch.tensor(rand / np.sum(rand, 1)[:, None])\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, soft_targets):\n",
    "    eps = np.zeros(out_gt.shape) + 1e-9\n",
    "    return torch.mean(torch.sum(- soft_targets * torch.log(pred + eps), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7447, dtype=torch.float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(out_gt, out_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9839, dtype=torch.float64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(out_target, out_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0668, dtype=torch.float64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(rand, out_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
